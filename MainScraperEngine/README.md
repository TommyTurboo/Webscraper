# MainScraperEngine v2.0 - Refactored Architecture

## ğŸ“ Project Structuur

```
MainScraperEngine/
â”œâ”€â”€ MSE.py                   â† CLI entry point (hoofdscript)
â”œâ”€â”€ Vendor_YML.yaml          â† Alle vendor configuraties
â”œâ”€â”€ __init__.py              â† Package marker
â”‚
â”œâ”€â”€ core/                    â† Core scraper logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scraper.py           â† ConfigDrivenScraper class
â”‚   â”œâ”€â”€ detector.py          â† Vendor detection
â”‚   â”œâ”€â”€ config.py            â† YAML config loader
â”‚   â””â”€â”€ utils.py             â† Text cleaning helpers
â”‚
â”œâ”€â”€ extractors/              â† Modular extractors (hybrid approach)
â”‚   â”œâ”€â”€ __init__.py          â† EXTRACTOR_REGISTRY
â”‚   â”œâ”€â”€ base.py              â† Abstract BaseExtractor class
â”‚   â”‚
â”‚   â”œâ”€â”€ generic/             â† Generic cross-vendor extractors
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ table.py         â† HTML <table> extractor
â”‚   â”‚   â”œâ”€â”€ dl.py            â† Definition list <dl> extractor
â”‚   â”‚   â”œâ”€â”€ rows.py          â† Row-based structures (VEGA, Nexans)
â”‚   â”‚   â”œâ”€â”€ li_split.py      â† LI split extractor (Siemens)
â”‚   â”‚   â”œâ”€â”€ label_value.py   â† Regex pattern extractor (fallback)
â”‚   â”‚   â”œâ”€â”€ datasheet.py     â† Generic datasheet link finder
â”‚   â”‚   â”œâ”€â”€ image.py         â† Generic image URL extractor (+ JSON-LD)
â”‚   â”‚   â””â”€â”€ meta_description.py â† Meta tag extractor
â”‚   â”‚
â”‚   â””â”€â”€ vendors/             â† Vendor-specific extractors (complex cases)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ schneider/
â”‚       â”‚   â””â”€â”€ json_parser.py  â† Schneider JSON-in-HTML extractor
â”‚       â””â”€â”€ nexans/
â”‚           â””â”€â”€ variants.py     â† Nexans product variants extractor
â”‚
â””â”€â”€ vendors/                 â† (Future) Split YAML configs per vendor
    â”œâ”€â”€ siemens.yaml
    â”œâ”€â”€ phoenix.yaml
    â””â”€â”€ ...
```

---

## ğŸ¯ Hybrid Extractor Strategie

### **Wanneer Generic Extractor?**
âœ… Gebruik generic extractor als:
- Simpele CSS selector verschillen
- Zelfde data model (key-value, table, list)
- Alleen presentatie verschilt (class names)

### **Wanneer Vendor-Specific Extractor?**
âœ… Maak vendor-specific extractor als:
- Logica > 50 regels voor 1 vendor
- Unieke data structuur (Schneider JSON, Nexans variants)
- Complexe transformaties (URL constructie, data merging)
- Vendor gebruikt API i.p.v. HTML scraping

---

## ğŸš€ Gebruik

### **Basic Usage:**
```bash
python MSE.py                           # Default test file
python MSE.py path/to/product.html      # Scrape specific file
```

### **Programmatic Usage:**
```python
from core.scraper import scrape_file, scrape_html

# Scrape from file
result = scrape_file("product.html")

# Scrape from HTML string
result = scrape_html(html_string)

# Result structure
{
  "vendor": "Siemens",
  "kv": {
    "Section Name": {
      "Key": "Value",
      ...
    }
  },
  "stats": {
    "table": 10,
    "datasheet_link": 1,
    ...
  },
  "metadata": {
    "canonical_url": "https://...",
    "extraction_timestamp": "31/01/2026 12:00:00"
  }
}
```

---

## ğŸ“ YAML Configuratie

### **Vendor toevoegen:**
```yaml
new_vendor:
  name: "New Vendor"
  priority: 25  # Lower = checked earlier
  
  detect:
    - selector: ".unique-class"
    - text_contains: "vendor name"
  
  specs:
    - type: "table"
      container: ".product-specs"
      tables: "table"
    
    - type: "datasheet_link"
      selectors:
        - "a[href*='datasheet']"
      target_section: "Downloads"
      target_key: "Datasheet"
```

### **Extractor Types:**

| Type | Gebruik | Generic/Vendor |
|------|---------|----------------|
| `table` | HTML tabellen | âœ… Generic |
| `dl` | Definition lists | âœ… Generic |
| `rows` | Row-based (VEGA) | âœ… Generic |
| `li_split` | LI split (Siemens) | âœ… Generic |
| `datasheet_link` | PDF datasheet finder | âœ… Generic |
| `attribute` | Image URLs | âœ… Generic |
| `meta_description` | Meta tags | âœ… Generic |
| `schneider_json` | Schneider JSON parser | âš ï¸ Vendor-specific |
| `product_variants` | Nexans variants | âš ï¸ Vendor-specific |

---

## ğŸ”§ Nieuwe Extractor Toevoegen

### **1. Generic Extractor (bijv. nieuwe "gallery" type):**

**Stap 1:** Maak `extractors/generic/gallery.py`:
```python
from typing import Dict, Any
from bs4 import BeautifulSoup
from extractors.base import BaseExtractor

class GalleryExtractor(BaseExtractor):
    @property
    def extractor_type(self) -> str:
        return "gallery"
    
    def extract(self, soup: BeautifulSoup, spec: Dict, kv: Dict) -> int:
        # Implementation...
        pass
```

**Stap 2:** Voeg toe aan `extractors/generic/__init__.py`:
```python
from extractors.generic.gallery import GalleryExtractor

__all__ = [
    # ...existing...
    "GalleryExtractor",
]
```

**Stap 3:** Registreer in `extractors/__init__.py`:
```python
EXTRACTOR_REGISTRY = {
    # ...existing...
    "gallery": GalleryExtractor,
}
```

**Stap 4:** Gebruik in YAML:
```yaml
siemens:
  specs:
    - type: "gallery"
      selector: ".product-gallery"
      target_section: "Images"
```

---

### **2. Vendor-Specific Extractor (bijv. Phoenix PDF parser):**

**Stap 1:** Maak folder `extractors/vendors/phoenix/`

**Stap 2:** Maak `extractors/vendors/phoenix/__init__.py`:
```python
from extractors.vendors.phoenix.pdf_parser import PhoenixPDFExtractor

__all__ = ["PhoenixPDFExtractor"]
```

**Stap 3:** Maak `extractors/vendors/phoenix/pdf_parser.py`:
```python
from extractors.base import BaseExtractor

class PhoenixPDFExtractor(BaseExtractor):
    @property
    def extractor_type(self) -> str:
        return "phoenix_pdf"
    
    def extract(self, soup, spec, kv):
        # Complex Phoenix-specific logic...
        pass
```

**Stap 4:** Registreer in `extractors/__init__.py`:
```python
from extractors.vendors.phoenix import PhoenixPDFExtractor

EXTRACTOR_REGISTRY = {
    # ...
    "phoenix_pdf": PhoenixPDFExtractor,
}
```

---

## ğŸ› Debugging

### **Test specific extractor:**
```python
from extractors.generic.datasheet import DatasheetLinkExtractor
from bs4 import BeautifulSoup

html = "<html>...</html>"
soup = BeautifulSoup(html, "html.parser")
kv = {}

extractor = DatasheetLinkExtractor()
count = extractor.extract(soup, {"selectors": ["a[href*='.pdf']"]}, kv)

print(f"Extracted {count} items: {kv}")
```

### **Test vendor detection:**
```python
from core.detector import detect_vendor
from core.config import load_configs
from bs4 import BeautifulSoup

configs = load_configs()
soup = BeautifulSoup(html, "html.parser")
vendor = detect_vendor(soup, configs)

print(f"Detected: {vendor}")
```

---

## ğŸ“Š Refactor Wins

| Metric | Old MSE.py | New (Refactored) |
|--------|-----------|------------------|
| **Lines of code** | 965 | ~50 (CLI) + modules |
| **Extractors** | Monolithic class | 12 modular files |
| **Testability** | Hard | Easy (isolated units) |
| **Maintainability** | âš ï¸ Medium | âœ… High |
| **Extensibility** | âš ï¸ Medium | âœ… High |

---

## ğŸ”„ Migration from v1.0

### **Code Changes:**
**Old:**
```python
from MSE import scrape_html
result = scrape_html(html)
```

**New:**
```python
from core.scraper import scrape_html
result = scrape_html(html)  # Same API!
```

### **YAML:**
No changes needed! `Vendor_YML.yaml` is fully compatible.

---

## ğŸ“š Next Steps

- [ ] Split `Vendor_YML.yaml` into separate files per vendor (`vendors/siemens.yaml`, etc.)
- [ ] Add unit tests per extractor (`tests/test_datasheet.py`, etc.)
- [ ] Create abstract `VendorExtractor` base class for complex vendors
- [ ] Add logging system (vendor detection, extractor performance)
- [ ] Implement caching for repeated scrapes

---

## ğŸ“ Architecture Philosophy

**"Start Generic, Specialize When Needed"**

1. **First:** Try to solve with generic extractors
2. **If 3+ fallbacks needed:** Consider vendor-specific
3. **If > 100 lines:** Definitely vendor-specific
4. **Keep YAML simple:** Complex logic â†’ Python extractor

This keeps the codebase **DRY** while allowing **vendor expertise** where needed.

---

## ğŸ¤ Contributing

Nieuwe vendor toevoegen:
1. Voeg detection rules toe aan `Vendor_YML.yaml`
2. Probeer eerst generic extractors
3. Maak vendor-specific extractor als nodig
4. Update deze README

---

## ğŸ“„ License

[Your License Here]

---

**Happy Scraping! ğŸš€**
